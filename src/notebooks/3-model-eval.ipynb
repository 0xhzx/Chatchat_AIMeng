{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLEASE REMEMBER TO CLEAR THE GPU MEMORY AFTER EACH STEP!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/Chatchat_AIMeng/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Chatchat_AIMeng/venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Chatchat_AIMeng/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "import torch\n",
    "import os\n",
    "## Downloading Model \n",
    "from utils.constants import *\n",
    "from utils.util_funcs import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "train_tokenized = load_from_disk('data/processed/train_tokenized')\n",
    "val_tokenized = load_from_disk('data/processed/val_tokenized')\n",
    "test_tokenized = load_from_disk('data/processed/test_tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=FINE_TUNED_MODEL_PATH,\n",
    "    save_total_limit=SAVE_TOTAL_LIMIT,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    evaluation_strategy=EVALUATION_STRATEGY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_original_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the trainer and eval on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=loaded_original_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='356' max='356' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [356/356 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = trainer.evaluate(eval_dataset=test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 39.28157043457031,\n",
       " 'eval_runtime': 50.671,\n",
       " 'eval_samples_per_second': 28.063,\n",
       " 'eval_steps_per_second': 7.026}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loaded_original_model\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After fine tune with 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH = os.path.join(MODEL_DIR, 'save')\n",
    "\n",
    "fintuned_model = AutoModelForSeq2SeqLM.from_pretrained(SAVE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=fintuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='356' max='356' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [356/356 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetuned_eval_results = trainer.evaluate(eval_dataset=test_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.16730812191963196,\n",
       " 'eval_runtime': 49.9755,\n",
       " 'eval_samples_per_second': 28.454,\n",
       " 'eval_steps_per_second': 7.123}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result represents the evaluation of the model before and after fine-tuning. Each dictionary contains the following keys:\n",
    "\n",
    "- `eval_loss`: The loss value of the model on the evaluation dataset. The lower the loss value, the better the performance of the model.\n",
    "- `eval_runtime`: The runtime of the evaluation process, in seconds.\n",
    "- `eval_samples_per_second`: The number of samples processed per second. The higher this value, the faster the model processes.\n",
    "- `eval_steps_per_second`: The number of steps executed per second. The higher this value, the faster the model processes.\n",
    "From these results, you can see that the loss value of the model on the evaluation dataset has significantly reduced after fine-tuning, from 39.28 to 0.17, indicating a significant improvement in the performance of the model.\n",
    "\n",
    "At the same time, the processing speed of the model has also improved after fine-tuning, with eval_samples_per_second increasing from 28.063 to 28.454, and eval_steps_per_second increasing from 7.026 to 7.123. This indicates that the model has also made some improvements in processing speed.\n",
    "\n",
    "In summary, these results show that fine-tuning has had a positive impact on both the performance and processing speed of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before fine tune: {'eval_loss': 39.28157043457031, 'eval_runtime': 50.671, 'eval_samples_per_second': 28.063, 'eval_steps_per_second': 7.026}\n",
      "==========================Compared==========================\n",
      "after fine tune: {'eval_loss': 0.16730812191963196, 'eval_runtime': 49.9755, 'eval_samples_per_second': 28.454, 'eval_steps_per_second': 7.123}\n"
     ]
    }
   ],
   "source": [
    "print(\"before fine tune:\",eval_results)\n",
    "print(\"==========================Compared==========================\")\n",
    "print(\"after fine tune:\",finetuned_eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fintuned_model\n",
    "clear_gpu_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
