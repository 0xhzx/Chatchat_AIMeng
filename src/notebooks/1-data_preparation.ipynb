{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "Nvidia Documentation Question and Answer pairs Q&A dataset for LLM finetuning about the NVIDIA about SDKs and blogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- -----------\n",
      "accelerate                               0.29.3\n",
      "aiofiles                                 23.2.1\n",
      "aiohttp                                  3.9.5\n",
      "aiosignal                                1.3.1\n",
      "annotated-types                          0.6.0\n",
      "anyio                                    3.7.1\n",
      "asttokens                                2.4.1\n",
      "async-timeout                            4.0.3\n",
      "asyncer                                  0.0.2\n",
      "attrs                                    23.2.0\n",
      "bidict                                   0.23.1\n",
      "certifi                                  2024.2.2\n",
      "chainlit                                 1.0.504\n",
      "charset-normalizer                       3.3.2\n",
      "chevron                                  0.14.0\n",
      "click                                    8.1.7\n",
      "comm                                     0.2.2\n",
      "dataclasses-json                         0.5.14\n",
      "debugpy                                  1.8.1\n",
      "decorator                                5.1.1\n",
      "Deprecated                               1.2.14\n",
      "distro                                   1.9.0\n",
      "exceptiongroup                           1.2.1\n",
      "executing                                2.0.1\n",
      "fastapi                                  0.110.2\n",
      "fastapi-socketio                         0.0.10\n",
      "filelock                                 3.13.4\n",
      "filetype                                 1.2.0\n",
      "frozenlist                               1.4.1\n",
      "fsspec                                   2024.3.1\n",
      "googleapis-common-protos                 1.63.0\n",
      "greenlet                                 3.0.3\n",
      "grpcio                                   1.62.2\n",
      "h11                                      0.14.0\n",
      "httpcore                                 1.0.5\n",
      "httpx                                    0.27.0\n",
      "huggingface-hub                          0.22.2\n",
      "idna                                     3.7\n",
      "importlib-metadata                       7.0.0\n",
      "ipykernel                                6.29.4\n",
      "ipython                                  8.23.0\n",
      "jedi                                     0.19.1\n",
      "Jinja2                                   3.1.3\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              2.4\n",
      "jupyter_client                           8.6.1\n",
      "jupyter_core                             5.7.2\n",
      "langchain                                0.1.16\n",
      "langchain-community                      0.0.34\n",
      "langchain-core                           0.1.45\n",
      "langchain-text-splitters                 0.0.1\n",
      "langsmith                                0.1.49\n",
      "Lazify                                   0.4.0\n",
      "literalai                                0.0.504\n",
      "MarkupSafe                               2.1.5\n",
      "marshmallow                              3.21.1\n",
      "matplotlib-inline                        0.1.7\n",
      "mpmath                                   1.3.0\n",
      "multidict                                6.0.5\n",
      "mypy-extensions                          1.0.0\n",
      "nest-asyncio                             1.6.0\n",
      "networkx                                 3.3\n",
      "numpy                                    1.26.4\n",
      "nvidia-cublas-cu12                       12.1.3.1\n",
      "nvidia-cuda-cupti-cu12                   12.1.105\n",
      "nvidia-cuda-nvrtc-cu12                   12.1.105\n",
      "nvidia-cuda-runtime-cu12                 12.1.105\n",
      "nvidia-cudnn-cu12                        8.9.2.26\n",
      "nvidia-cufft-cu12                        11.0.2.54\n",
      "nvidia-curand-cu12                       10.3.2.106\n",
      "nvidia-cusolver-cu12                     11.4.5.107\n",
      "nvidia-cusparse-cu12                     12.1.0.106\n",
      "nvidia-nccl-cu12                         2.19.3\n",
      "nvidia-nvjitlink-cu12                    12.4.127\n",
      "nvidia-nvtx-cu12                         12.1.105\n",
      "openai                                   1.6.1\n",
      "opentelemetry-api                        1.24.0\n",
      "opentelemetry-exporter-otlp              1.24.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.24.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.24.0\n",
      "opentelemetry-exporter-otlp-proto-http   1.24.0\n",
      "opentelemetry-instrumentation            0.45b0\n",
      "opentelemetry-proto                      1.24.0\n",
      "opentelemetry-sdk                        1.24.0\n",
      "opentelemetry-semantic-conventions       0.45b0\n",
      "orjson                                   3.10.1\n",
      "packaging                                23.2\n",
      "parso                                    0.8.4\n",
      "pexpect                                  4.9.0\n",
      "pinecone-client                          3.2.2\n",
      "pip                                      23.0.1\n",
      "platformdirs                             4.2.0\n",
      "prompt-toolkit                           3.0.43\n",
      "protobuf                                 4.25.3\n",
      "psutil                                   5.9.8\n",
      "ptyprocess                               0.7.0\n",
      "pure-eval                                0.2.2\n",
      "pydantic                                 2.7.0\n",
      "pydantic_core                            2.18.1\n",
      "Pygments                                 2.17.2\n",
      "PyJWT                                    2.8.0\n",
      "pypdf                                    3.8.1\n",
      "python-dateutil                          2.9.0.post0\n",
      "python-dotenv                            1.0.1\n",
      "python-engineio                          4.9.0\n",
      "python-graphql-client                    0.4.3\n",
      "python-multipart                         0.0.9\n",
      "python-socketio                          5.11.2\n",
      "PyYAML                                   6.0.1\n",
      "pyzmq                                    26.0.2\n",
      "regex                                    2024.4.16\n",
      "requests                                 2.31.0\n",
      "safetensors                              0.4.3\n",
      "setuptools                               65.5.0\n",
      "simple-websocket                         1.0.0\n",
      "six                                      1.16.0\n",
      "sniffio                                  1.3.1\n",
      "SQLAlchemy                               2.0.29\n",
      "stack-data                               0.6.3\n",
      "starlette                                0.37.2\n",
      "sympy                                    1.12\n",
      "syncer                                   2.0.3\n",
      "tenacity                                 8.2.3\n",
      "tiktoken                                 0.3.3\n",
      "tokenizers                               0.19.1\n",
      "tomli                                    2.0.1\n",
      "torch                                    2.2.2\n",
      "tornado                                  6.4\n",
      "tqdm                                     4.66.2\n",
      "traitlets                                5.14.3\n",
      "transformers                             4.40.0\n",
      "triton                                   2.2.0\n",
      "typing_extensions                        4.11.0\n",
      "typing-inspect                           0.9.0\n",
      "uptrace                                  1.24.0\n",
      "urllib3                                  2.2.1\n",
      "uvicorn                                  0.25.0\n",
      "watchfiles                               0.20.0\n",
      "wcwidth                                  0.2.13\n",
      "websockets                               12.0\n",
      "wrapt                                    1.16.0\n",
      "wsproto                                  1.2.0\n",
      "yarl                                     1.9.4\n",
      "zipp                                     3.18.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is important for import other packages from another directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/Chatchat_AIMeng/src\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Chatchat_AIMeng/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.constants import RANDOM_SEED\n",
    "from utils.util_funcs import data_cleaning\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ajsbsd/nvidia-qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'question', 'answer'],\n",
       "        num_rows: 7108\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'question', 'answer'],\n",
       "    num_rows: 7108\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset['train']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'question', 'answer'],\n",
       "        num_rows: 5686\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'question', 'answer'],\n",
       "        num_rows: 1422\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=RANDOM_SEED)\n",
    "dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'question', 'answer'],\n",
       "    num_rows: 5686\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset_split['train']\n",
    "test_dataset = dataset_split['test']\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'question', 'answer'],\n",
       "        num_rows: 4548\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'question', 'answer'],\n",
       "        num_rows: 1138\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_dataset = train_dataset.train_test_split(test_size=0.2, seed=RANDOM_SEED)\n",
    "train_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_val_dataset['train']\n",
    "val_dataset = train_val_dataset['test']\n",
    "test_dataset = test_dataset # original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'question', 'answer'],\n",
       "    num_rows: 4548\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'question', 'answer'],\n",
       "    num_rows: 1422\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'question', 'answer'],\n",
       "    num_rows: 1138\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_dataset)\n",
    "test_df = pd.DataFrame(test_dataset)\n",
    "val_df = pd.DataFrame(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5189</td>\n",
       "      <td>What limitation does cuBLAS-XT solve for GPU a...</td>\n",
       "      <td>cuBLAS-XT overcomes the limitation of manually...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4339</td>\n",
       "      <td>What is the role of the NVIDIA CUDA compiler i...</td>\n",
       "      <td>The NVIDIA CUDA compiler optimizes memory reso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1398</td>\n",
       "      <td>What are the two ways to modify behavior in th...</td>\n",
       "      <td>The two ways to modify behavior in the system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2457</td>\n",
       "      <td>How does the cudaMemAdvise API enhance memory ...</td>\n",
       "      <td>The cudaMemAdvise API provides memory usage hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2157</td>\n",
       "      <td>What kind of measurement is used to compare fl...</td>\n",
       "      <td>The comparison of floating-point results betwe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0        5189  What limitation does cuBLAS-XT solve for GPU a...   \n",
       "1        4339  What is the role of the NVIDIA CUDA compiler i...   \n",
       "2        1398  What are the two ways to modify behavior in th...   \n",
       "3        2457  How does the cudaMemAdvise API enhance memory ...   \n",
       "4        2157  What kind of measurement is used to compare fl...   \n",
       "\n",
       "                                              answer  \n",
       "0  cuBLAS-XT overcomes the limitation of manually...  \n",
       "1  The NVIDIA CUDA compiler optimizes memory reso...  \n",
       "2  The two ways to modify behavior in the system ...  \n",
       "3  The cudaMemAdvise API provides memory usage hi...  \n",
       "4  The comparison of floating-point results betwe...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove useless columns\n",
    "train_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "test_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "val_df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/raw/train.csv', index=False)\n",
    "test_df.to_csv('data/raw/test.csv', index=False)\n",
    "val_df.to_csv('data/raw/val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4548, step=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./data/processed/train.csv').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4548 entries, 0 to 4547\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  4548 non-null   object\n",
      " 1   answer    4548 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 71.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['question'] = train_df['question'].apply(data_cleaning)\n",
    "val_df['question'] = val_df['question'].apply(data_cleaning)\n",
    "test_df['question'] = test_df['question'].apply(data_cleaning)\n",
    "\n",
    "train_df['answer'] = train_df['answer'].apply(data_cleaning)\n",
    "val_df['answer'] = val_df['answer'].apply(data_cleaning)\n",
    "test_df['answer'] = test_df['answer'].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what limitation does cublasxt solve for gpu ac...</td>\n",
       "      <td>cublasxt overcomes the limitation of manually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the role of the nvidia cuda compiler i...</td>\n",
       "      <td>the nvidia cuda compiler optimizes memory reso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are the two ways to modify behavior in th...</td>\n",
       "      <td>the two ways to modify behavior in the system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how does the cudamemadvise api enhance memory ...</td>\n",
       "      <td>the cudamemadvise api provides memory usage hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what kind of measurement is used to compare fl...</td>\n",
       "      <td>the comparison of floatingpoint results betwee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>what is the connection between the lowpower gk...</td>\n",
       "      <td>the lowpower gk208 gpu present in the geforce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>how does unified memory impact the development...</td>\n",
       "      <td>unified memory simplifies memory management in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>how can loop unrolling improve cuda code perfo...</td>\n",
       "      <td>loop unrolling is a technique that reduces loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>which digitized manuscripts were used for the ...</td>\n",
       "      <td>the study conducted by the university of notre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>what percentage of supercomputers in the top 5...</td>\n",
       "      <td>nearly 50 supercomputers in the top 500 list u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4548 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     what limitation does cublasxt solve for gpu ac...   \n",
       "1     what is the role of the nvidia cuda compiler i...   \n",
       "2     what are the two ways to modify behavior in th...   \n",
       "3     how does the cudamemadvise api enhance memory ...   \n",
       "4     what kind of measurement is used to compare fl...   \n",
       "...                                                 ...   \n",
       "4543  what is the connection between the lowpower gk...   \n",
       "4544  how does unified memory impact the development...   \n",
       "4545  how can loop unrolling improve cuda code perfo...   \n",
       "4546  which digitized manuscripts were used for the ...   \n",
       "4547  what percentage of supercomputers in the top 5...   \n",
       "\n",
       "                                                 answer  \n",
       "0     cublasxt overcomes the limitation of manually ...  \n",
       "1     the nvidia cuda compiler optimizes memory reso...  \n",
       "2     the two ways to modify behavior in the system ...  \n",
       "3     the cudamemadvise api provides memory usage hi...  \n",
       "4     the comparison of floatingpoint results betwee...  \n",
       "...                                                 ...  \n",
       "4543  the lowpower gk208 gpu present in the geforce ...  \n",
       "4544  unified memory simplifies memory management in...  \n",
       "4545  loop unrolling is a technique that reduces loo...  \n",
       "4546  the study conducted by the university of notre...  \n",
       "4547  nearly 50 supercomputers in the top 500 list u...  \n",
       "\n",
       "[4548 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/processed/train.csv', index=False)\n",
    "test_df.to_csv('data/processed/test.csv', index=False)\n",
    "val_df.to_csv('data/processed/val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/processed/train.csv')\n",
    "test_df = pd.read_csv('data/processed/test.csv')\n",
    "val_df = pd.read_csv('data/processed/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df)\n",
    "val_data = Dataset.from_pandas(val_df)\n",
    "test_data = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 4548\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/Chatchat_AIMeng/src'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GenerationConfig\n",
    "from utils.util_funcs import tokenized_batch_function\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "hf_token = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4548/4548 [00:04<00:00, 1070.85 examples/s]\n",
      "Map: 100%|██████████| 1138/1138 [00:00<00:00, 1350.38 examples/s]\n",
      "Map: 100%|██████████| 1422/1422 [00:01<00:00, 1288.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = train_data.map(lambda x: tokenized_batch_function(x, hf_token = hf_token), batched=True)\n",
    "val_tokenized = val_data.map(lambda x: tokenized_batch_function(x,hf_token = hf_token), batched=True)\n",
    "test_tokenized = test_data.map(lambda x: tokenized_batch_function(x,hf_token = hf_token), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'input_ids', 'labels'],\n",
       "    num_rows: 4548\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = train_tokenized.select_columns([\"input_ids\", \"labels\"])\n",
    "val_tokenized = val_tokenized.select_columns([\"input_ids\", \"labels\"])\n",
    "test_tokenized = test_tokenized.select_columns([\"input_ids\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels'],\n",
       "    num_rows: 4548\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[148,\n",
       "  33,\n",
       "  3,\n",
       "  9,\n",
       "  11860,\n",
       "  18,\n",
       "  188,\n",
       "  29,\n",
       "  7,\n",
       "  3321,\n",
       "  53,\n",
       "  6165,\n",
       "  5,\n",
       "  2150,\n",
       "  12,\n",
       "  8,\n",
       "  826,\n",
       "  822,\n",
       "  10,\n",
       "  125,\n",
       "  14130,\n",
       "  405,\n",
       "  123,\n",
       "  4605,\n",
       "  7,\n",
       "  226,\n",
       "  17,\n",
       "  4602,\n",
       "  21,\n",
       "  3,\n",
       "  122,\n",
       "  4987,\n",
       "  23224,\n",
       "  947,\n",
       "  33,\n",
       "  128,\n",
       "  207,\n",
       "  4269,\n",
       "  10,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized['input_ids'][0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 4548/4548 [00:00<00:00, 154267.95 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1138/1138 [00:00<00:00, 103117.83 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1422/1422 [00:00<00:00, 114817.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_tokenized.save_to_disk('data/processed/train_tokenized')\n",
    "val_tokenized.save_to_disk('data/processed/val_tokenized')\n",
    "test_tokenized.save_to_disk('data/processed/test_tokenized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
